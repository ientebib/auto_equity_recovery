# Lead Recovery Codebase Maintenance Guide

This guide provides information on how to maintain the codebase and which files/directories are essential vs. non-essential.

## Core Directories

These directories are essential to the functioning of the lead recovery system:

- `lead_recovery/` - Main application code
  - `cli/` - Command-line interfaces
  - `processors/` - Data processing modules
- `recipes/` - Recipe configuration files
- `documentation/` - Project documentation
- `tests/` - Test cases (important for future development)

## Temporary/Generated Files (Safe to Delete)

These files are generated during runtime and can be safely deleted:

- `__pycache__/` directories - Python bytecode
- `*.pyc` files - Python compiled files
- `redshift_queried_*.marker` files - Old Redshift query markers
- Log files (`.log`) in the root directory - Runtime logs
- `.pytest_cache/` - Pytest cache

## Output Data (Consider Before Deleting)

- `output_run/` - Contains results from recipe runs
  - Consider keeping the most recent run for each recipe
  - Older runs can be deleted if space is needed

## Maintenance Tasks

### Regular Cleanup

Run the provided `cleanup.sh` script to automatically:
- Remove old marker files
- Clean Python cache directories
- Remove empty and debug log files
- Optionally clean old output runs (keeping only the latest for each recipe)
- Delete old log files

```bash
./cleanup.sh
```

### Pruning Output Directories

If disk space becomes an issue, you can safely prune the `output_run` directory:

```bash
# Keep only the most recent output for each recipe
for recipe_dir in output_run/*/; do
  if [ -d "$recipe_dir" ]; then
    recipe_name=$(basename "$recipe_dir")
    echo "Cleaning old runs for recipe: $recipe_name"
    
    # Get latest output directory
    latest_dir=$(find "$recipe_dir" -maxdepth 1 -type d -name "20*" | sort | tail -n 1)
    
    if [ -n "$latest_dir" ]; then
      # Remove all other timestamp directories
      find "$recipe_dir" -maxdepth 1 -type d -name "20*" | grep -v "$latest_dir" | xargs rm -rf
    fi
  fi
done
```

## Obsolete Components

The following components are no longer used or have been replaced:

1. **Deprecated Processor Files (Already Removed)**
   - `lead_recovery/processors/temporal_processor.py` - Replaced by `temporal.py`
   - `lead_recovery/processors/message_metadata_processor.py` - Replaced by `metadata.py`
   - `python_flags_manager.py` (legacy flag logic, replaced by processor-level controls)

2. **Legacy Directory**
   - The `legacy/` directory contains old recipe versions that are no longer maintained.
   - It is not removed automatically by `cleanup.sh`. Delete it manually if the recipes are no longer needed.

3. **Test Output Directory**
   - `test_output_run/` is used only for testing and can be deleted.

## Do Not Delete

Never delete these critical configuration files:

- `.env` - Environment variables configuration
- `pyproject.toml` and `requirements.txt` - Dependency definitions
- `meta.yml` files in recipes - Recipe configurations

## Git Cleanup

To clean the Git repository from large files that are no longer needed:

```bash
# Remove large files from Git history (use with caution)
git filter-branch --force --tree-filter 'rm -f path/to/large/file' HEAD
git gc --aggressive
git prune
```

## Database Cleanup

The SQlite cache database (`data/cache/summary_cache.sqlite`) can grow large over time. You can safely delete this file to reclaim space, but it will cause the system to regenerate summaries for conversations:

```bash
rm data/cache/summary_cache.sqlite
```

## Schema Versioning and Recipe Maintenance

- Ensure all recipes have `recipe_schema_version: 2` in their meta.yml files.
- When processors are added or changed, use the processor registry to update `output_columns` in each recipe.
- See the Python Processors Guide for details on using the registry.

### Troubleshooting
- **Schema Version Errors:** Ensure your meta.yml includes `recipe_schema_version: 2` at the root.
- **Missing Columns:** Use the processor registry to check which columns are generated by each processor and include them in `output_columns`.

- The old flag system is now fully deprecated. Use processor-level controls and output_columns in meta.yml for all new recipes.

## Automated Validation in CI/Pre-commit

To ensure all recipes remain compliant, add `scripts/validate_all_recipes.py` to your CI pipeline or as a pre-commit hook. This will prevent schema drift and output column errors.

- **CI Example:**
  - Add a step to your GitHub Actions or other CI config:
    ```yaml
    - name: Validate all recipes
      run: python scripts/validate_all_recipes.py
    ```
- **Pre-commit Example:**
  - Add to `.pre-commit-config.yaml`:
    ```yaml
    -   repo: local
        hooks:
        -   id: validate-recipes
            name: Validate all recipes
            entry: python scripts/validate_all_recipes.py
            language: system
            types: [yaml]
    ```

## Safe Processor Flag Management

When adding or removing processors (flags) in a recipe's `meta.yml`:
- **Add a processor:**
  1. Add the processor to the `python_processors` list.
  2. Use the processor registry to get its output columns:
     ```python
     from lead_recovery.processors._registry import get_columns_for_processor
     print(get_columns_for_processor("YourProcessorClassName"))
     ```
  3. Add these columns to `output_columns` if not already present.
  4. Run the validation script to confirm compliance.

- **Remove a processor:**
  1. Remove it from `python_processors`.
  2. Remove its columns from `output_columns` (unless produced by another processor or LLM key).
  3. Run the validation script to confirm compliance.

- **Add/remove LLM keys:**
  1. Update `llm_config.expected_llm_keys`.
  2. Add/remove the key in `output_columns` as needed.
  3. Run the validation script.

### Troubleshooting
- **Validation fails for a column:**
  - Check if the column is produced by a processor or LLM key.
  - If it's a lead info column, add it to the whitelist in the validation script.
- **Output column missing in CSV:**
  - Ensure the processor is active and the column is in `GENERATED_COLUMNS`.
  - Ensure the column is in `output_columns`. 