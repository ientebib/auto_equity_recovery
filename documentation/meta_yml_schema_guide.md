# Guide to meta.yml Schema (Version 2.0)

## Schema Versioning

All recipes must include a `recipe_schema_version: 2` field at the root of their meta.yml. This is required for validation and migration tooling. If you see a schema version error, update your meta.yml accordingly.

## Processor Registry and Output Columns

When defining `output_columns`, use the processor registry to ensure all columns generated by your active processors are included. See the Python Processors Guide for details on using the registry.

### Troubleshooting
- **Schema Version Errors:** Ensure your meta.yml includes `recipe_schema_version: 2` at the root.
- **Missing Columns:** Use the processor registry to check which columns are generated by each processor and include them in `output_columns`.

This document describes the structure and fields for the `meta.yml` recipe configuration file,
as defined by the Pydantic schema in `lead_recovery/recipe_schema.py`.
This schema ensures consistency, clarity, and validation for all recipes.

## Root Configuration (`RecipeMeta`)

The `meta.yml` file is a YAML representation of the `RecipeMeta` model.

**Mandatory Root Fields:**

* `recipe_name` (string, required):
    * **Description:** Unique name for the recipe. Must match the recipe's directory name.
    * **Example:** `profiling_incomplete`
* `data_input` (object, required):
    * **Description:** Defines how the recipe sources its primary lead data and conversation data. See [Data Input Configuration](#data-input-configuration) below.
* `output_columns` (list of strings, required):
    * **Description:** Defines ALL columns that will appear in the final output CSV, in the specified order. This list must include:
        1.  Key fields from the lead data source (e.g., `lead_id`).
        2.  All keys listed in `llm_config.expected_llm_keys` (if LLM is used and the key is not optional or intended to be omitted).
        3.  All fields generated by active `python_processors`.
    * **Example:**
        ```yaml
        output_columns:
          - lead_id
          - conversation_id
          - llm_summary_field # From LLM
          - python_calculated_flag # From a PythonProcessor
          - another_lead_data_field
        ```

**Optional Root Fields:**

* `description` (string, optional):
    * **Description:** A brief human-readable description of what the recipe does.
    * **Example:** `Analyzes conversations for incomplete profiling and identifies stall reasons.`
* `version` (string, optional, defaults to "1.0"):
    * **Description:** Version of the recipe configuration itself.
    * **Example:** `1.1`
* `llm_config` (object, optional):
    * **Description:** Configuration for interacting with the Language Model (LLM). This entire section can be omitted if the recipe does not use an LLM. See [LLM Configuration](#llm-configuration) below.
* `python_processors` (list of objects, optional, defaults to empty list `[]`):
    * **Description:** A list defining the Python processing modules to be run for this recipe. These are the evolution of "Python flags." The order in this list might be significant if processors depend on each other's output. See [Python Processor Configuration](#python-processor-configuration) below.
* `custom_analyzer_module` (string, optional):
    * **Description:** Fully qualified Python path to a custom analyzer class (e.g., `recipes.my_recipe.analyzer.MyCustomAnalyzer`). Use this for complex, unique analysis that doesn't fit the standard `python_processors` model. Prefer `python_processors` where possible.
* `custom_analyzer_params` (object, optional, defaults to empty object `{}`):
    * **Description:** Parameters to be passed to the `custom_analyzer_module` if specified.
    * **Example:**
        ```yaml
        custom_analyzer_params:
          threshold: 0.75
          mode: "detailed"
        ```

**Strictness:**
* No extra fields beyond those defined in this schema are allowed at the root of the `meta.yml` file (`Config.extra = 'forbid'`).

---

## Data Input Configuration (`data_input`)

This section is mandatory and defines the data sources for the recipe.

* `lead_source_type` (string, required):
    * **Description:** Specifies the primary source of lead data.
    * **Allowed Values:** `redshift`, `bigquery`, `csv`
* `redshift_config` (object, conditionally required):
    * **Description:** Configuration if `lead_source_type` is `redshift`. Must be omitted otherwise.
    * `sql_file` (string, required): Filename of the Redshift SQL script (relative to the recipe directory) to fetch lead data.
    * **Example:**
        ```yaml
        data_input:
          lead_source_type: redshift
          redshift_config:
            sql_file: my_redshift_leads.sql
        ```
* `bigquery_config` (object, conditionally required):
    * **Description:** Configuration if `lead_source_type` is `bigquery`. Must be omitted otherwise.
    * `sql_file` (string, required): Filename of the BigQuery SQL script (relative to the recipe directory) to fetch lead data.
* `csv_config` (object, conditionally required):
    * **Description:** Configuration if `lead_source_type` is `csv`. Must be omitted otherwise.
    * `csv_file` (string, required): Filename of the CSV file (relative to the recipe directory) containing lead data.
* `conversation_sql_file_redshift` (string, optional):
    * **Description:** Specific Redshift SQL filename (relative to recipe directory) to fetch conversation data for leads. If omitted and Redshift is used, a default mechanism might be used (e.g., a standard conversation query script).
* `conversation_sql_file_bigquery` (string, optional):
    * **Description:** Specific BigQuery SQL filename (relative to recipe directory) to fetch conversation data for leads. If omitted and BigQuery is used, a default mechanism might be used.

---

## LLM Configuration (`llm_config`)

This section is optional. Include it only if the recipe uses an LLM.

* `prompt_file` (string, optional, defaults to `prompt.txt`):
    * **Description:** Filename of the prompt template (relative to the recipe directory).
* `expected_llm_keys` (object, optional, defaults to empty object `{}`):
    * **Description:** A dictionary where each key is a field name you expect the LLM to return in its YAML output. The value is an object defining the configuration for that key (see `LLMKeyConfig` below).
    * **Example:**
        ```yaml
        expected_llm_keys:
          summary:
            description: "A concise summary of the conversation."
            type: str
          sentiment_score:
            description: "A numerical sentiment score from -1.0 to 1.0."
            type: float
            is_optional: true
          category:
            description: "The primary category of the issue."
            type: str
            enum_values: ["Billing", "Technical Support", "Sales Inquiry"]
        ```
* `context_keys_from_python` (list of strings, optional):
    * **Description:** A list of keys (field names) that are generated by `python_processors`. The values of these keys will be made available as context variables within the LLM prompt template.
    * **Example:** `["user_message_count", "days_since_last_contact"]`

### `LLMKeyConfig` (structure for each key within `expected_llm_keys`)

* `description` (string, optional): Human-readable description of the field.
* `type` (string, optional, defaults to `str`): The expected data type.
    * **Allowed Values:** `str`, `int`, `float`, `bool`, `list`, `dict`
* `enum_values` (list, optional): A list of allowed exact values if the field is an enumeration.
* `is_optional` (boolean, optional, defaults to `false`): If `true`, this key is not strictly required in the LLM's output.

---

## Python Processor Configuration (`python_processors`)

This section is optional (defaults to an empty list). It defines a list of Python analysis modules to be executed.

Each item in the list is an object with the following fields:
* `module` (string, required):
    * **Description:** The fully qualified Python import path to the processor class.
    * **Example:** `lead_recovery.processors.temporal.TemporalProcessor`
* `params` (object, optional, defaults to empty object `{}`):
    * **Description:** A dictionary of parameters to be passed to this specific processor instance during its initialization.
    * **Example:**
        ```yaml
        python_processors:
          - module: "lead_recovery.processors.keyword_counter.KeywordCounter"
            params:
              keywords_to_count: ["urgent", "asap", "complaint"]
          - module: "lead_recovery.processors.temporal.TemporalProcessor"
        ``` 