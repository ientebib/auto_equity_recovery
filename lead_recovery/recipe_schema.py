# PATH: lead_recovery/recipe_schema.py
from pydantic import BaseModel, Field, validator
from typing import List, Dict, Optional, Union, Literal, Any
from pathlib import Path # Keep Path for type hinting if resolved paths are Path objects

class LLMKeyConfig(BaseModel):
    """Defines expected characteristics of a single key generated by the LLM."""
    description: Optional[str] = None # Optional description of what this key represents
    type: Literal['str', 'int', 'float', 'bool', 'list', 'dict'] = 'str'
    enum_values: Optional[List[Union[str, int, float, bool]]] = None # Allowed enum values if applicable
    is_optional: bool = False # If true, the key is not strictly required in LLM output

class LLMConfig(BaseModel):
    """Configuration for LLM interaction."""
    prompt_file: str = "prompt.txt" # Default prompt filename, relative to recipe dir
    expected_llm_keys: Dict[str, LLMKeyConfig] = {} # Fields the LLM is expected to generate
    # Python-generated keys that should be available as context variables in the prompt
    context_keys_from_python: Optional[List[str]] = None

class DataInputSQL(BaseModel):
    """Configuration for SQL-based data input."""
    sql_file: str # Filename of the SQL script, relative to recipe dir
    # connection_name: Optional[str] = "default" # Future: to select from pre-configured db connections

class DataInputCSV(BaseModel):
    """Configuration for CSV-based data input."""
    csv_file: str # Filename of the CSV, relative to recipe dir

class DataInputConfig(BaseModel):
    """Defines the primary source for lead data."""
    lead_source_type: Literal['redshift', 'bigquery', 'csv']
    redshift_config: Optional[DataInputSQL] = None
    bigquery_config: Optional[DataInputSQL] = None
    csv_config: Optional[DataInputCSV] = None

    # Validator to ensure that the correct config sub-model is provided based on lead_source_type
    @validator('redshift_config', always=True)
    def check_redshift_config(cls, v, values):
        if values.get('lead_source_type') == 'redshift' and v is None:
            raise ValueError("redshift_config must be provided when lead_source_type is 'redshift'")
        if values.get('lead_source_type') != 'redshift' and v is not None:
            raise ValueError("redshift_config should only be provided when lead_source_type is 'redshift' (and not for other types)")
        return v

    @validator('bigquery_config', always=True)
    def check_bigquery_config(cls, v, values):
        if values.get('lead_source_type') == 'bigquery' and v is None:
            raise ValueError("bigquery_config must be provided when lead_source_type is 'bigquery'")
        if values.get('lead_source_type') != 'bigquery' and v is not None:
            raise ValueError("bigquery_config should only be provided when lead_source_type is 'bigquery' (and not for other types)")
        return v

    @validator('csv_config', always=True)
    def check_csv_config(cls, v, values):
        if values.get('lead_source_type') == 'csv' and v is None:
            raise ValueError("csv_config must be provided when lead_source_type is 'csv'")
        if values.get('lead_source_type') != 'csv' and v is not None:
            raise ValueError("csv_config should only be provided when lead_source_type is 'csv' (and not for other types)")
        return v
    
    # Configuration for fetching conversation data.
    # These are filenames relative to the recipe directory.
    conversation_sql_file_redshift: Optional[str] = None
    conversation_sql_file_bigquery: Optional[str] = None

class PythonProcessorConfig(BaseModel):
    """Configuration for a single Python processing module/flag group."""
    module: str  # Fully qualified Python path to the processor class
                 # e.g., "lead_recovery.processors.temporal.TemporalProcessor"
    params: Optional[Dict[str, Any]] = Field(default_factory=dict) # Specific parameters for this processor instance

class RecipeMeta(BaseModel):
    """Root model for the recipe meta.yml configuration."""
    recipe_name: str = Field(..., min_length=1, description="Unique name for the recipe. Should match directory name.")
    description: Optional[str] = None
    version: str = "1.0"

    data_input: DataInputConfig
    llm_config: Optional[LLMConfig] = None # Entire LLM block is optional for Python-only recipes

    python_processors: Optional[List[PythonProcessorConfig]] = Field(default_factory=list)
    
    output_columns: List[str]

    custom_analyzer_module: Optional[str] = None 
    custom_analyzer_params: Optional[Dict[str, Any]] = Field(default_factory=dict)

    class Config:
        extra = 'forbid' # Disallow any extra fields not defined in the schema at the root level
        validate_assignment = True # Ensure validation happens on assignment too 