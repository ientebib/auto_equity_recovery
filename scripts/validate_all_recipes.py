#!/usr/bin/env python3
"""
Validate All Recipes Script

Checks all recipes for:
- Schema compliance (using RecipeMeta)
- All output_columns are either LLM keys, generated by the listed processors, or whitelisted lead info columns

Usage:
  python scripts/validate_all_recipes.py
  python scripts/validate_all_recipes.py --only <recipe_name_or_path>
"""
import sys
from pathlib import Path
import yaml
import argparse
from lead_recovery.recipe_schema import RecipeMeta
from lead_recovery.processors._registry import get_columns_for_processor

# Ensure all processors are registered
import lead_recovery.processors.temporal
import lead_recovery.processors.metadata
import lead_recovery.processors.handoff
import lead_recovery.processors.template
import lead_recovery.processors.validation
import lead_recovery.processors.conversation_state
import lead_recovery.processors.human_transfer

RECIPES_DIR = Path(__file__).resolve().parent.parent / "recipes"

# Whitelist of standard lead info columns (add more as needed)
LEAD_COLUMNS = set([
    "cleaned_phone", "lead_id", "user_id", "lead_created_at", "name", "last_name", "Email", "Asset ID", "Last Bureua Score", "Max Loan", "Nombre", "Cohort", "Control Group", "Initial Step", "Initial Step Date", "Last Step", "Last Step Date", "Bill Date", "handoff_reached", "cache_status"
])

def validate_recipe(recipe_dir):
    meta_path = recipe_dir / "meta.yml"
    if not meta_path.exists():
        print(f"[SKIP] {recipe_dir.name}: No meta.yml found.")
        return 0
    try:
        with open(meta_path, "r") as f:
            meta = yaml.safe_load(f)
        # Validate schema
        RecipeMeta(**meta)
        # Build set of valid columns
        valid_columns = set()
        # LLM keys
        llm_keys = set()
        if "llm_config" in meta and meta["llm_config"] and "expected_llm_keys" in meta["llm_config"]:
            llm_keys = set(meta["llm_config"]["expected_llm_keys"].keys())
        valid_columns.update(llm_keys)
        # Processor columns
        if "python_processors" in meta:
            for proc in meta["python_processors"]:
                if isinstance(proc, dict) and "module" in proc:
                    class_name = proc["module"].split(".")[-1]
                    valid_columns.update(get_columns_for_processor(class_name))
        # Check output_columns
        missing = []
        for col in meta.get("output_columns", []):
            if col not in valid_columns and col not in LEAD_COLUMNS:
                missing.append(col)
        if missing:
            print(f"[FAIL] {recipe_dir.name}: output_columns not produced by LLM, processors, or whitelisted as lead columns: {missing}")
            return 1
        else:
            print(f"[OK]   {recipe_dir.name}")
            return 0
    except Exception as e:
        print(f"[ERROR] {recipe_dir.name}: {e}")
        return 1

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--only', type=str, default=None, help='Validate only the given recipe (name or path)')
    args = parser.parse_args()
    failures = 0
    if args.only:
        # Accept either a recipe name or a path
        recipe_dir = Path(args.only)
        if not recipe_dir.is_dir():
            # Try as a name in RECIPES_DIR
            recipe_dir = RECIPES_DIR / args.only
        failures += validate_recipe(recipe_dir)
    else:
        for recipe_dir in RECIPES_DIR.iterdir():
            if recipe_dir.is_dir():
                failures += validate_recipe(recipe_dir)
    if failures:
        print(f"\nValidation failed for {failures} recipe(s). See above for details.")
        sys.exit(1)
    else:
        print("\nAll recipes validated successfully.")

if __name__ == "__main__":
    main() 